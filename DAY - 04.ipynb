{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64e93425-ec5c-44f4-bc93-e23e213eed52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"/Volumes/workspace/ecommerce/ecommerce_data/stream_input\")\n",
    "print(\"Stream input folder created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "664e84d9-7594-43bf-85aa-3ffc21c680d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load bronze table\n",
    "events = spark.table(\"workspace.ecommerce.events_delta\")\n",
    "\n",
    "# Take small sample\n",
    "sample_df = events.limit(1000)\n",
    "\n",
    "# Write CSV files DIRECTLY to stream_input folder (important fix)\n",
    "sample_df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\n",
    "\"/Volumes/workspace/ecommerce/ecommerce_data/stream_input\"\n",
    ")\n",
    "print(\"Sample files written directly to stream_input folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3aebc95-0592-43fc-b6ec-4d52abeae354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stream_df = spark.readStream \\\n",
    "    .schema(events.schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"/Volumes/workspace/ecommerce/ecommerce_data/stream_input\")\n",
    "\n",
    "print(\"Streaming DataFrame created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cfd1d45-dcaf-47a8-ba8f-7e9458bfa060",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = stream_df.writeStream \\\n",
    ".format(\"delta\") \\\n",
    ".outputMode(\"append\") \\\n",
    ".trigger(availableNow=True) \\\n",
    ".option(\n",
    "    \"checkpointLocation\",\n",
    "    \"/Volumes/workspace/ecommerce/ecommerce_data/checkpoints/stream_chk\"\n",
    "    ) \\\n",
    "    .start(\"/Volumes/workspace/ecommerce/ecommerce_data/stream_output\")\n",
    "\n",
    "print(\"Streaming job started ... \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a6b16dd-9d7f-4d96-a416-7687da3dbdf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for q in spark.streams.active:\n",
    "    print(\"Stopping stream:\", q.id)\n",
    "    q.stop()\n",
    "\n",
    "print(\"All active streams stopped. \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59510376-4a6b-46a4-ae57-57acc3176ce8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(\n",
    "\"/Volumes/workspace/ecommerce/ecommerce_data/checkpoints/stream_chk\",\n",
    "True\n",
    ")\n",
    "print(\"Old checkpoint folder cleared successfully!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DAY - 04",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
